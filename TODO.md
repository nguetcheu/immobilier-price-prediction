# üìã TODO - Projet Pr√©diction Prix Immobiliers

## üéØ R√©partition des T√¢ches

### Membre 1 : NGUETCHEU KUINSI Dominique
**Responsable** : Phases 1 - 6

### Membre 2 : WENJI PASCAL Victor
**Responsable** : Phases 1 - 6

### Collaboration : Phase 7

---

## Phase 1 : Exploration (EDA) üîç 
**Script** : `scripts/01_exploration.py`  
**Responsable** : Membre 1

- [ ] Charger le dataset (`pandas.read_csv`)
- [ ] Afficher les premi√®res lignes et info du dataset
- [ ] Statistiques descriptives (`describe()`)
- [ ] V√©rifier les types de donn√©es
- [ ] Cr√©er histogrammes pour toutes les variables num√©riques
- [ ] Cr√©er boxplots pour d√©tecter les outliers
- [ ] Calculer matrice de corr√©lation
- [ ] Visualiser heatmap des corr√©lations
- [ ] Identifier corr√©lations avec la cible (prix)
- [ ] Compter et visualiser les valeurs manquantes
- [ ] Documenter les outliers identifi√©s
- [ ] R√©diger conclusions pr√©liminaires

**Livrables** :
- Notebook compl√©t√©
- 5-10 visualisations sauvegard√©es dans `results/figures/`
- Fichier `data/processed/eda_summary.csv` avec statistiques

---

## Phase 2 : Feature Engineering üõ†Ô∏è  
**Notebook** : `02_feature_engineering.ipynb`  
**Responsable** : Membre 1

### 2.1 Cr√©ation de Features
- [ ] `surface_par_piece` = surface totale / nombre de pi√®ces
- [ ] `prix_par_m2` = prix / surface (si disponible)
- [ ] `age_propriete` = ann√©e actuelle - ann√©e construction
- [ ] `ratio_chambres` = chambres / pi√®ces totales
- [ ] Features d'interaction (ex: `surface * nb_pieces`)

### 2.2 Variables Cat√©goriques
- [ ] Identifier toutes les variables cat√©goriques
- [ ] One-Hot Encoding pour variables avec peu de modalit√©s (<10)
- [ ] Label Encoding ou Target Encoding pour variables nombreuses
- [ ] V√©rifier absence de multicolin√©arit√© apr√®s encoding

### 2.3 Valeurs Manquantes
- [ ] Strat√©gie pour chaque colonne (m√©diane, mode, pr√©diction)
- [ ] Impl√©menter imputation intelligente
- [ ] Cr√©er indicatrices de valeurs manquantes si pertinent
- [ ] Documenter choix d'imputation

### 2.4 Normalisation
- [ ] StandardScaler pour variables num√©riques
- [ ] V√©rifier distribution apr√®s scaling
- [ ] Sauvegarder scaler pour r√©utilisation

**Livrables** :
- Notebook compl√©t√©
- Dataset transform√© : `data/processed/features_engineered.csv`
- Fichier `src/feature_engineering.py` avec fonctions r√©utilisables

---

## Phase 3 : Feature Selection üéØ
**Notebook** : `03_feature_selection.ipynb`  
**Responsable** : Membre 1

### 3.1 M√©thode 1 : Tree-Based Importance
- [ ] Entra√Æner RandomForest sur toutes les features
- [ ] Extraire `feature_importances_`
- [ ] Visualiser top 20 features

### 3.2 M√©thode 2 : Permutation Importance
- [ ] Utiliser `sklearn.inspection.permutation_importance`
- [ ] Calculer sur mod√®le Random Forest
- [ ] Comparer avec m√©thode 1

### 3.3 M√©thode 3 : Corr√©lation
- [ ] Calculer corr√©lation Pearson avec cible
- [ ] S√©lectionner features avec |corr| > 0.3
- [ ] Identifier features redondantes (corr entre elles > 0.9)

### 3.4 S√©lection Finale
- [ ] Croiser les 3 m√©thodes
- [ ] S√©lectionner top 15 features
- [ ] Entra√Æner mod√®le avec toutes features (baseline)
- [ ] Entra√Æner mod√®le avec 15 features s√©lectionn√©es
- [ ] Comparer performances (RMSE, R¬≤, temps d'entra√Ænement)

**Livrables** :
- Liste finale de 15 features dans `results/selected_features.txt`
- Graphiques de comparaison
- Dataset r√©duit : `data/processed/features_selected.csv`

---

## Phase 4 : Mod√©lisation ü§ñ
**Notebook** : `04_modelisation.py`  
**Responsable** : Membre 2

### 4.1 Pr√©paration
- [ ] Charger dataset avec features s√©lectionn√©es
- [ ] Split train/test (70/30)
- [ ] D√©finir fonction d'√©valuation (RMSE, R¬≤, MAE)

### 4.2 Mod√®les √† Entra√Æner
- [ ] **Linear Regression** (baseline)
  - Entra√Ænement
  - Cross-validation 5-fold
  - M√©triques

- [ ] **Ridge Regression**
  - Tester alpha = [0.1, 1, 10, 100]
  - Cross-validation 5-fold
  - M√©triques

- [ ] **Random Forest**
  - Param√®tres par d√©faut
  - Cross-validation 5-fold
  - M√©triques

- [ ] **Gradient Boosting** (XGBoost ou LightGBM)
  - Param√®tres par d√©faut
  - Cross-validation 5-fold
  - M√©triques

### 4.3 Comparaison
- [ ] Tableau comparatif des 4 mod√®les
- [ ] Graphique barplot des m√©triques
- [ ] Identifier le meilleur mod√®le
- [ ] Analyser temps d'entra√Ænement

**Livrables** :
- Notebook compl√©t√©
- Fichier `results/metrics/models_comparison.csv`
- 4 mod√®les sauvegard√©s dans `models/`

---

## Phase 5 : Optimisation ‚öôÔ∏è
**Deadline** : [Date]  
**Notebook** : `05_optimisation.py`  
**Responsable** : Membre 2

### 5.1 Choix du Mod√®le
- [ ] S√©lectionner le meilleur mod√®le de la Phase 4
- [ ] Documenter pourquoi ce mod√®le

### 5.2 GridSearchCV
- [ ] D√©finir grille d'hyperparam√®tres (3-4 param√®tres cl√©s)
  - Exemple Random Forest : `n_estimators`, `max_depth`, `min_samples_split`
  - Exemple Gradient Boosting : `learning_rate`, `n_estimators`, `max_depth`
- [ ] Configurer GridSearchCV (cv=5, scoring='neg_mean_squared_error')
- [ ] Lancer optimisation (peut prendre du temps !)
- [ ] Extraire meilleurs param√®tres

### 5.3 √âvaluation
- [ ] Entra√Æner mod√®le avec param√®tres par d√©faut
- [ ] Entra√Æner mod√®le avec param√®tres optimis√©s
- [ ] Comparer m√©triques avant/apr√®s
- [ ] Calculer gain de performance (%)

**Livrables** :
- Meilleurs hyperparam√®tres dans `results/best_params.json`
- Mod√®le optimis√© : `models/best_model_tuned.pkl`
- Comparaison avant/apr√®s

---

## Phase 6 : Pipeline & Validation üîÑ
**Deadline** : [Date]  
**Notebook** : `06_pipeline_validation.py`  
**Responsable** : Membre 2

### 6.1 Pipeline Complet
- [ ] Cr√©er Pipeline sklearn :
  ```
  Pipeline([
    ('scaler', StandardScaler()),
    ('feature_selection', SelectKBest(k=15)),
    ('model', BestModelTuned())
  ])
  ```
- [ ] Tester pipeline sur donn√©es brutes

### 6.2 √âvaluation Test Set
- [ ] Charger donn√©es de test (30% s√©par√©s au d√©but)
- [ ] Pr√©dictions avec pipeline
- [ ] Calculer m√©triques finales (RMSE, R¬≤, MAE)
- [ ] Comparer avec m√©triques de validation

### 6.3 Analyse des Erreurs
- [ ] Calculer r√©sidus (y_true - y_pred)
- [ ] Graphique Actual vs Predicted (scatter plot)
- [ ] Graphique r√©sidus vs pr√©dictions
- [ ] Identifier top 10 pires pr√©dictions
- [ ] Analyser pourquoi le mod√®le se trompe

### 6.4 Visualisations Finales
- [ ] Distribution des r√©sidus (histogramme)
- [ ] QQ-plot des r√©sidus
- [ ] Feature importance du mod√®le final
- [ ] Courbes d'apprentissage (learning curves)

**Livrables** :
- Pipeline complet : `models/final_pipeline.pkl`
- Fichier `results/metrics/final_evaluation.csv`
- 5-8 visualisations dans `results/figures/`

---

## Phase 7 : Rapport & Recommandations üìä
**Deadline** : [Date]  
**Document** : `reports/rapport_final.md` ou `.pdf`  
**Responsable** : **COLLABORATION MEMBRE 1 + MEMBRE 2**

### 7.1 Structure du Rapport (3-5 pages)

#### Introduction
- [ ] Contexte du projet
- [ ] Probl√©matique
- [ ] Objectifs

#### M√©thodologie
- [ ] Description du dataset
- [ ] Approche feature engineering
- [ ] Mod√®les test√©s
- [ ] M√©thode d'√©valuation

#### R√©sultats
- [ ] Performances des mod√®les (tableau)
- [ ] Meilleur mod√®le et param√®tres
- [ ] M√©triques finales sur test set
- [ ] Visualisations cl√©s (3-4 graphiques)

#### Analyse
- [ ] Features les plus importantes
- [ ] Cas d'usage bien pr√©dits
- [ ] Cas probl√©matiques
- [ ] R√©sidus et erreurs

#### Recommandations pour l'Agence Immobili√®re
- [ ] Comment utiliser le mod√®le
- [ ] Fourchette de confiance des pr√©dictions
- [ ] Facteurs cl√©s influen√ßant le prix
- [ ] Strat√©gies d'√©valuation immobili√®re

#### Limitations et Perspectives
- [ ] Limites du mod√®le actuel
- [ ] Donn√©es suppl√©mentaires souhaitables
- [ ] Am√©liorations futures
- [ ] Risques et pr√©cautions

#### Conclusion
- [ ] Synth√®se des r√©sultats
- [ ] R√©ponse √† la probl√©matique

### 7.2 Annexes
- [ ] Code source principal
- [ ] Graphiques compl√©mentaires
- [ ] R√©f√©rences

**Livrables** :
- Rapport final (PDF)
- Pr√©sentation PowerPoint (10-15 slides)
- Code source propre et comment√©

---

### Documentation
- [ ] README.md √† jour
- [ ] Chaque notebook a une introduction claire
- [ ] `requirements.txt` complet
- [ ] Commentaires dans le code
